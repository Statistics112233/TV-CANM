{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clAD99xq3VTW"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "###################### Load dataset (replace with actual dataset loading) #################################\n",
        "def load_target_data():\n",
        "    data = pd.read_csv('Data_File.csv')  # Ensure your file is named correctly\n",
        "    x = data['Age'].values\n",
        "    y = data['Target'].values\n",
        "    return x, y\n",
        "\n",
        "####################### HSIC (Hilbert-Schmidt Independence Criterion) computation with optional sigma tuning#############################\n",
        "def HSIC(X, Y, sigma_X=None, sigma_Y=None, epsilon=1e-8):\n",
        "    n = X.shape[0]\n",
        "\n",
        "    # If no custom sigma is provided, use the median heuristic\n",
        "    if sigma_X is None:\n",
        "        sigma_X = np.median(np.abs(X[:, None] - X[None, :]))\n",
        "    if sigma_Y is None:\n",
        "        sigma_Y = np.median(np.abs(Y[:, None] - Y[None, :]))\n",
        "\n",
        "    # Compute RBF kernel matrices for X and Y\n",
        "    K = np.exp(-np.square(X[:, None] - X[None, :]) / (2 * sigma_X ** 2 + epsilon))\n",
        "    L = np.exp(-np.square(Y[:, None] - Y[None, :]) / (2 * sigma_Y ** 2 + epsilon))\n",
        "\n",
        "    # Centering matrix\n",
        "    H = np.eye(n) - (1.0 / n) * np.ones((n, n))\n",
        "\n",
        "    # HSIC value calculation\n",
        "    HSIC_value = np.trace(np.dot(np.dot(K, H), np.dot(L, H))) / (n - 1) ** 2\n",
        "    return HSIC_value\n",
        "\n",
        "# Additive Noise Model (ANM) using Linear Regression and HSIC\n",
        "def ANM_LR(x, y):\n",
        "    # Split the data into training and test sets\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "    # Standardize the data\n",
        "    scaler_x = StandardScaler()\n",
        "    scaler_y = StandardScaler()\n",
        "    x_train_scaled = scaler_x.fit_transform(x_train.reshape(-1, 1))\n",
        "    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1))\n",
        "    x_test_scaled = scaler_x.transform(x_test.reshape(-1, 1))\n",
        "    y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "    # Linear Regression model for Age -> Target\n",
        "    model_xy = LinearRegression()\n",
        "    model_xy.fit(x_train_scaled, y_train_scaled.ravel())\n",
        "    y_pred_xy = model_xy.predict(x_test_scaled)\n",
        "    residuals_xy = y_test_scaled.ravel() - y_pred_xy\n",
        "\n",
        "    # Linear Regression model for Target -> Age\n",
        "    model_yx = LinearRegression()\n",
        "    model_yx.fit(y_train_scaled, x_train_scaled.ravel())\n",
        "    x_pred_yx = model_yx.predict(y_test_scaled)\n",
        "    residuals_yx = x_test_scaled.ravel() - x_pred_yx\n",
        "\n",
        "    # Compute HSIC for both directions with manual sigma tuning (you can adjust sigma if needed)\n",
        "    HSIC_xy = HSIC(x_test_scaled.ravel(), residuals_xy)\n",
        "    HSIC_yx = HSIC(y_test_scaled.ravel(), residuals_yx)\n",
        "\n",
        "    # Compute MSE for both directions\n",
        "    mse_xy = mean_squared_error(y_test_scaled, y_pred_xy)\n",
        "    mse_yx = mean_squared_error(x_test_scaled, x_pred_yx)\n",
        "\n",
        "    return {'HSIC_xy': HSIC_xy, 'HSIC_yx': HSIC_yx, 'MSE_xy': mse_xy, 'MSE_yx': mse_yx}\n",
        "\n",
        "# Main function to infer causal direction and calculate MSE\n",
        "def infer_causal_direction():\n",
        "    # Load your dataset\n",
        "    x, y = load_target_data()\n",
        "\n",
        "    # Apply ANM_LR to infer causal direction using Linear Regression\n",
        "    result = ANM_LR(x, y)\n",
        "\n",
        "    # Determine causal direction based on HSIC\n",
        "    if result['HSIC_xy'] < result['HSIC_yx']:\n",
        "        causal_direction = \"Age -> Target\"\n",
        "    else:\n",
        "        causal_direction = \"Target -> Age\"\n",
        "\n",
        "    # Output the results\n",
        "    print(f'Causal direction: {causal_direction}')\n",
        "    print(f'HSIC (Age -> Target): {result[\"HSIC_xy\"]:.4f}')\n",
        "    print(f'HSIC (Target -> Age): {result[\"HSIC_yx\"]:.4f}')\n",
        "    print(f'MSE (Age -> Target): {result[\"MSE_xy\"]:.4f}')\n",
        "    print(f'MSE (Target -> Age): {result[\"MSE_yx\"]:.4f}')\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    infer_causal_direction()\n",
        "\n",
        "######################### Apply IGCI ########################################\n",
        "\n",
        "def igci_score(x, y, refMeasure=2, estimator=1, epsilon=1e-8):\n",
        "    # Ensure data is sorted for proper evaluation\n",
        "    idx = np.argsort(x)\n",
        "    x = x[idx]\n",
        "    y = y[idx]\n",
        "\n",
        "    if refMeasure == 1:\n",
        "        # Ref Measure: Uniform\n",
        "        delta_x = np.diff(x)\n",
        "        delta_y = np.diff(y)\n",
        "    elif refMeasure == 2:\n",
        "        # Ref Measure: Gaussian\n",
        "        delta_x = np.diff(stats.norm.cdf(x))\n",
        "        delta_y = np.diff(stats.norm.cdf(y))\n",
        "    else:\n",
        "        raise ValueError(\"refMeasure should be 1 (Uniform) or 2 (Gaussian)\")\n",
        "\n",
        "    # Add a small epsilon to avoid division by zero\n",
        "    delta_x = np.clip(delta_x, epsilon, None)\n",
        "    delta_y = np.clip(delta_y, epsilon, None)\n",
        "\n",
        "    # Compute the IGCI score based on the estimator chosen\n",
        "    if estimator == 1:\n",
        "        score = np.sum(np.log(np.abs(delta_y)) - np.log(np.abs(delta_x)))\n",
        "    elif estimator == 2:\n",
        "        score = np.mean(np.log(np.abs(delta_y / delta_x)))\n",
        "    else:\n",
        "        raise ValueError(\"estimator should be 1 or 2\")\n",
        "\n",
        "    return score\n",
        "\n",
        "# Apply IGCI method to determine causal direction and get scores\n",
        "def apply_igci(x, y):\n",
        "    # Apply IGCI score in both directions\n",
        "    score_xy = igci_score(x, y, refMeasure=2, estimator=1)\n",
        "    score_yx = igci_score(y, x, refMeasure=2, estimator=1)\n",
        "\n",
        "    # Determine causal direction based on the scores\n",
        "    if score_xy < score_yx:\n",
        "        causal_direction = \"Age -> Target\"\n",
        "    else:\n",
        "        causal_direction = \"Target -> Age\"\n",
        "\n",
        "    return causal_direction, score_xy, score_yx\n",
        "\n",
        "######## Load your dataset\n",
        "def load_height_data():\n",
        "    data = pd.read_csv('Data_File.csv')  # Ensure your file is named correctly\n",
        "    age = data['Age'].values\n",
        "    target = data['Target'].values\n",
        "    return age, target\n",
        "\n",
        "# Main function to apply IGCI and display average scores\n",
        "if __name__ == \"__main__\":\n",
        "    age, target = load_target_data()\n",
        "\n",
        "    # Apply IGCI method\n",
        "    causal_direction, score_xy, score_yx = apply_igci(age, target)\n",
        "\n",
        "    # Display the results\n",
        "    print(f'Causal direction: {causal_direction}')\n",
        "    print(f'Average IGCI score (Age -> Target): {score_xy:.4f}')\n",
        "    print(f'Average IGCI score (Height -> Target): {score_yx:.4f}')\n",
        "\n",
        "\n",
        "############################## Apply CAM model ##############################################\n",
        "# Load and preprocess data\n",
        "data = pd.read_csv(\"Data_File.csv\")\n",
        "data['Age'] = (data['Age'] - data['Age'].mean()) / data['Age'].std()\n",
        "data['Target'] = (data['Target'] - data['Target'].mean()) / data['Target'].std()\n",
        "\n",
        "# Prepare data for both directions\n",
        "X_age_to_target = data[['Age']].values\n",
        "y_age_to_target = data['Target'].values\n",
        "X_target_to_age = data[['Target']].values\n",
        "y_target_to_age = data['Age'].values\n",
        "\n",
        "# Fit CAM model and track loss scores in both directions\n",
        "_, loss_age_to_target = fit_cam_and_track_loss(X_age_to_target, y_age_to_target)\n",
        "_, loss_target_to_age = fit_cam_and_track_loss(X_target_to_age, y_target_to_age)\n",
        "\n",
        "# Calculate average loss over the last 10 epochs for each direction\n",
        "avg_loss_age_to_target = np.mean(loss_age_to_target[-10:])\n",
        "avg_loss_target_to_age = np.mean(loss_target_to_age[-10:])\n",
        "\n",
        "# Determine inferred direction\n",
        "direction = \"Age -> Target\" if avg_loss_age_to_target < avg_loss_target_to_age else \"Target -> Age\"\n",
        "\n",
        "# Print results\n",
        "print(\"\\nCAM Model Results Based on Average Loss:\")\n",
        "print(f\"  Avg Loss Age -> Target: {avg_loss_age_to_target}\")\n",
        "print(f\"  Avg Loss target -> Age: {avg_loss_target_to_age}\")\n",
        "print(f\"Inferred Causal Direction: {direction}\")\n",
        "\n",
        "# Plotting loss convergence for visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(loss_age_to_target, label='CAM Age -> Target', color='blue')\n",
        "plt.plot(loss_target_to_age, label='CAM Target -> Age', color='orange', linestyle='--')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.title('Causal Direction Convergence for CAM')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "######################## Apply PNL and Loss-based causal inference ##############################\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "# Load and preprocess data\n",
        "data = pd.read_csv(\"Data_File.csv\")\n",
        "data['Age'] = (data['Age'] - data['Age'].mean()) / data['Age'].std()\n",
        "data['Target'] = (data['Target'] - data['Target'].mean()) / data['Target'].std()\n",
        "\n",
        "### 1. Improved PNL Model without Early Stopping ###\n",
        "class ImprovedNonlinearTransformation(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(ImprovedNonlinearTransformation, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 20)\n",
        "        self.bn1 = nn.BatchNorm1d(20)\n",
        "        self.fc2 = nn.Linear(20, 20)\n",
        "        self.bn2 = nn.BatchNorm1d(20)\n",
        "        self.fc3 = nn.Linear(20, 10)\n",
        "        self.bn3 = nn.BatchNorm1d(10)\n",
        "        self.fc4 = nn.Linear(10, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.relu(self.bn3(self.fc3(x)))\n",
        "        return self.fc4(x)\n",
        "\n",
        "class ImprovedPNLModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedPNLModel, self).__init__()\n",
        "        self.nonlinear_transformation = ImprovedNonlinearTransformation(1)\n",
        "        self.predictor = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_transformed = self.nonlinear_transformation(x)\n",
        "        return self.predictor(x_transformed)\n",
        "\n",
        "# Training function without early stopping\n",
        "def train_improved_pnl_model(train_x, train_y, epochs=500, lr=1e-3):\n",
        "    model = ImprovedPNLModel().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)  # L2 regularization\n",
        "    criterion = nn.MSELoss()\n",
        "    train_x, train_y = torch.FloatTensor(train_x).view(-1, 1), torch.FloatTensor(train_y).view(-1, 1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(train_x)\n",
        "        loss = criterion(output, train_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return model, loss.item()\n",
        "\n",
        "# Prepare data for both directions\n",
        "train_x_age_to_target, train_y_age_to_target = data['Age'].values, data['Target'].values\n",
        "train_x_target_to_age, train_y_target_to_age = data['Target'].values, data['Age'].values\n",
        "\n",
        "# Train improved PNL models for both directions\n",
        "_, loss_age_to_target = train_improved_pnl_model(train_x_age_to_target, train_y_age_to_target)\n",
        "_, loss_target_to_age = train_improved_pnl_model(train_x_target_to_age, train_y_target_to_age)\n",
        "\n",
        "# Determine the inferred causal direction based on lower loss\n",
        "direction = \"Age -> Target\" if loss_age_to_target < loss_target_to_age else \"Target -> Age\"\n",
        "print(f\"  Loss for Age -> Target: {loss_age_to_target}\")\n",
        "print(f\"  Loss for Target -> Age: {loss_target_to_age}\")\n",
        "print(f\"Inferred Causal Direction: {direction}\")\n",
        "\n",
        "\n",
        "################################### 4. Simple Neural Network Model for Dependency Measurement #############################\n",
        "class SimpleRegressor(nn.Module):\n",
        "    def __init__(self, input_dim=1, hidden_dim=10):\n",
        "        super(SimpleRegressor, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "def train_model(train_x, train_y, epochs=200, lr=1e-3):\n",
        "    model = SimpleRegressor().to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    train_x, train_y = torch.FloatTensor(train_x).view(-1, 1), torch.FloatTensor(train_y).view(-1, 1)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(train_x)\n",
        "        loss = criterion(output, train_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return model, loss.item()\n",
        "\n",
        "# Train models for both directions\n",
        "_, loss_age_to_target = train_model(train_x_age_to_target, train_y_age_to_target)\n",
        "_, loss_target_to_age = train_model(train_x_target_to_age, train_y_target_to_age)\n",
        "\n",
        "# Determine inferred causal direction based on lower loss\n",
        "direction = \"Age -> Target\" if loss_age_to_target < loss_target_to_age else \"Target -> Age\"\n",
        "print(\"\\nLoss-Based Causal Inference Results:\")\n",
        "print(f\"  Loss for Age -> Target: {loss_age_to_target}\")\n",
        "print(f\"  Loss for Target -> Age: {loss_target_to_age}\")\n",
        "print(f\"Inferred Causal Direction: {direction}\")\n"
      ]
    }
  ]
}
